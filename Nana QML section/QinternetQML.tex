%\documentclass[aps,prx,twocolumn,preprintnumbers,superscriptaddress]{revtex4} 

\documentclass[twocolumn, aps, rmp, amsmath, amssymb, nofootinbib, superscriptaddress, longbibliography, floatfix, table-of-contents, eqsecnum]{revtex4-2}


\usepackage[pdftex]{graphicx}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{adjustbox}


%% Useful packages
\usepackage[colorlinks, breaklinks]{hyperref}
\usepackage{hhline}


\begin{document}
%\maketitle

\noindent \textbf{Quantum internet and quantum machine learning}
%\author{Chris, Nana}

\tableofcontents 

\section{Introduction}

Today classical machine learning is affecting the understanding and better regulation of classical network systems which can be of use in the modern internet. These include pattern recognition for individual computing devices, security and fault management, routing and traffic management, resource management and distributed computation. In these applications, it is not only the speed of processing that is important, but reliability and security can be paramount.

The large intersection between machine learning and network systems (the internet included) is perhaps not surprising. Firstly, machine learning relies on access to data and in many real-life applications, data naturally arise from distributed sources. Secondly, especially for complex systems like large networks, the information to process is complex and contains many uncertainties and errors. Exactly solvable models in these regimes are few and far between, and machine learning may be helpful in making predictions in these messy environments.

In the coming quantum age we can envision three possible ways where quantum resources can come into our internet: quantum communication, quantum processing at individual nodes and data that is naturally quantum in origin. To begin, we first make a classification of the four different types of networks we can have: see Table~\eqref{tab:CommTable}. We can classify them into (i) CC (classical data and processing over classical network), or the current internet; (ii) CQ (classical data and processing over quantum network); (iii) QC (quantum data and processing over classical network) and (iv) QQ (quantum data and processing over quantum network), or a fully-quantum internet.

So now we can pose the inevitable question: how can these different quantum resources in a network influence the relationship between the internet and machine learning?

This is not yet an active research area in its own right. However, there are some preliminary toolkits we can consider that are starting to be developed in the new field of quantum machine learning. By first summarising the intersection between the classical internet and classical machine learning, it gives us an idea of the kinds of tools we need to begin examining their quantum counterparts. For instance, we will see how aspects of quantum processing of quantum data might be aided by machine learning, how machine learning may be enhanced by quantum resources and also in turn how machine learning may be implemented in these distributed quantum settings. See Table~\eqref{tab:CommTable2} for a brief overview. 

%It is natural to consider machine learning when we have an internet. Firstly, in machine learning applications, data naturally arise from distributed sources, so we begin from a network setting. There are also four main requirements we have in network settings (i) security (ii) speed and reliability of device information processing at each node (iii) speed and reliability of routing protocols (iv) speed and reliability of data transmission. Some of these may benefit from machine learning techniques. We then introduce quantum resources for two main reasons. The first is when the data we want to process is naturally quantum, so we wish to use machine learning to either diminish our resources to process this data or want to perform machine learning algorithms directly on this data. The second reason is that we exploit quantum resources to enhance the processing of classical data by means of machine learning.
%There are 3 parts to machine learning: data collection (offline or online); feature engineering and model learning.
\section{Classical machine learning in classical networks}
 To create and maintain an efficient classical network, one requires efficient and reliable processing on individual nodes, secure processing, efficient routing and data transmission, efficient uses of resources and a means for distributed information processing. For overview of methods see for example \cite{boutaba2018comprehensive}, \cite{wang2018machine}.  We give a brief overview on how machine learning can be used in each of these areas. 

\subsection{Machine learning basics for individual processors}
Machine learning algorithms enable one to make predictions about one's current or future dataset without requiring explicit instructions. Since its aims are directed more towards \textit{prediction} rather than purely \textit{estimation}, it differs from the field of statistical estimation even though it shares many common tools.

There are 3 mains paradigms for machine learning: supervised, unsupervised and reinforcement learning. Supervised learning relies on having training data from which to form inferences and to make predictions about new incoming `test' data. On the other hand, unsupervised learning algorithms make inferences using the data at hand without access to a training stage, much like a student learning without an instructor. Reinforcement learning operates using a different framework and aims to find the best action steps in a particular environment to maximize a given reward.

Machine learning is used regularly for data collection, feature engineering and model learning. There are many excellent references on this broad subject, for instance see the introductory texts \cite{bishop2006pattern, shalev2014understanding, trevor2009elements, marsland2011machine, flach2012machine}.

%\noindent $\bullet$ Two main classes of machine learning algorithms: discriminative and generative. Discriminative learning is about finding a description of the conditional probability ($P(A|B)$), i.e. given test $B$, what is the probability that it belongs to $A$? Generative modelling deals with generating new instances of the same class, so tries to recover the joint probability $P(A, B)$ if given a class set $A$. \\

\subsection{Machine learning for security and fault management}
There are two main ways in which  machine learning enters into managing security and faults in networks. The first is \textit{using} machine learning techniques to predict and detect security breeches and faults in a network. These include machine learning algorithms for anomaly detection. The second is studying the security vulnerabilities of machine learning algorithms themselves, as the presence of adversaries becomes natural in a network setting, where real-life machine learning algorithms will be deployed. The latter is known as adversarial machine learning.

\textit{Anomaly detection and fault management---} When there are security breeches in classical data on a network, one desires the ability to predict and detect these disturbances, as well as a method for making one's protocols more robust against these adversaries. Machine learning is often used in anomaly detection and intrusion detection. These algorithms look for unusual data or unusual changes in data. Broadly, there are three classes of anomalies: point, contextual and collective, which refer respectively to single datum anomalies, unusual data with respect to a specified context and clusters of data which together point to an unusual pattern. Both supervised and unsupervised algorithms are used for these settings \cite{thottan2003anomaly, ahmed2007machine}. One of the prime challenges here include determining the presence of an anomaly when little data is available and determining the relevant rate of false positives and false negatives for a particular application.

Fault management in a network is also extremely relevant, especially for complex networks where there is more room for errors. One requires the prediction, detection and localisation of the fault, and most relevant machine learning methods use supervised algorithms. However, the paucity of real training data (as opposed to synthetic data generated from simulations) means that the algorithms might be poorly trained, especially in new networks \cite{hood1997proactive, kogeda2006prediction, snow2005assessing}. This is expected to be true, for instance, when a quantum internet is first set up. To accommodate for this, new methods have arisen where unsupervised machine learning techniques are used instead to detect changes in the network rather relying on labelled fault data \cite{hajji2005statistical}.

In particular, to identify and localise unusual behaviour in a network which can be due to natural faults or an adversarial party, network anomaly detection methods can be employed \cite{ahmed2007machine}, \cite{fraley2017promise}, \cite{joseph2013machine}. Since the results can be sensitive to the training datasets used, it is important to examine which datasets are most appropriate for one's particular applications (see a review of datasets for anomaly detection \cite{yavanoglu2017review}). In particular, there have been many proposals on using anomaly detection in the network intrusion domain. However, this approach has been criticized for its uses in real-life applications since it's often difficult to distinguish anomalies
related to intrusions from those related to other factors and the complexity of real-life networks may make it too difficult to define what is a normal signal \cite{sommer2010outside}.

\textit{Adversarial machine learning---} Machine learning algorithms themselves are vulnerable to security attacks. This comes under the field of adversarial machine learning \cite{huang2011adversarial}. There are two main types of attacks: attacks of the test data (evasion) and attacks of the training data and the machine learning models (poisoning). In real-life deployments of machine learning, data often comes from different sources which makes adversarial attacks more probable. It has been discovered that many machine learning algorithms are in fact vulnerable to adversarial attacks, the first discovered in \cite{szegedy2013intriguing}. A large proportion of the literature then focuses on the details of specific algorithms: the detection of adversaries, their different methods of attack and the particular defenses to those attacks \cite{kurakin2018adversarial}. However, recently, more foundational work has emerged to try to explain the origins of this vulnerability as arising from the high dimensionality of the data involved \cite{goodfellow2014explaining, gilmer2018adversarial,mahloujifar2018curse}.

\subsection{Machine learning for traffic and routing management}
The effective operation of a network like an internet also requires automated management. This includes efficient means of traffic prediction, traffic classification, routing and congestion control. Machine learning algorithms have been developed for all these areas.

\textit{Traffic---} Predicting network traffic is becoming increasingly important especially in diverse and complex networks. It is commonly addressed using time-series forecasting (TSF) methods. This can make use of either statistical analysis models or supervised machine learning methods \cite{bermolen2009support, chabaa2010identification, cortez2006internet}]. Non-TSF methods also exist \cite{chen2016predicting, li2016inter}.

The most commonly-used technique for traffic classification is the so-called flow feature-based
technique. This takes into account information on unidirectional packets sent in the network. Supervised machine learning is found to be accurate in traffic classification in this domain. However, unsupervised techniques are found to be more robust. So the joint application of both supervised and unsupervised machine learning techniques have been found to be more powerful \cite{erman2007offline, zhang2015robust}.

\textit{Routing---} Machine learning is most applicable to routing problems where the network is dynamical and thus requires fast updating of new optimal routes. otherwise, already-made routing tables can be sufficient for networks. Since these settings depend on frequent updating on new data, reinforcement learning algorithms are the most appropriate. In particular, Q-learning has performed well in various different networks \cite{wang2006adaptive, forster2007froms, arroyo2007q}.

\textit{Congestion---} Congestion control in a network is also important to ensure the stability of a network and the minimisation of packet loss. Well-known congestion control methods like queue management already exist. However machine learning can be used to enhance the effectiveness of congestion control in various different networks, although mostly for TCP/IP networks \cite{liu2002end, barman2004model, el2005improving}. 

%\noindent $\bullet$ Resource allocation using ML. 
% network traffic control systems \cite{fadlullah2017state}
\subsection{Distributed machine learning}
Distributed machine learning is the scenario where communication between computing devices are necessary to execute the machine learning algorithm of interest.

These distributed algorithms can be executed over an internet and become highly relevant in the following scenarios: (i) When data used in the training and/or testing of the machine learning algorithm originates from different sources. This is the naturally-distributed setting. In these cases, it is also possible for the loading of all data onto one machine and transferring data may be too costly and interrupts the workflow. It can even be the case that this loading time is greater than computational time, so distributed computation is more resource-efficient; (ii) When data is too large to be stored on the RAM of a single machine; (iii) When fault tolerance becomes important. For instance, for sensitive data, if data is stored in multiple places, there is less likelihood of data corruption from any single source and the data would still be available if one source fails.

The toolbox and infrastructure for distributed machine learning is currently in rapid development. There are many algorithms available. For instance, see \cite{peteiro2013survey} for a survey. Also for distributed clustering see \cite{florian2013}. There are also systems available to cater to distributed machine learning, like MLbase \cite{MLbase}, Hadoop \cite{white2012hadoop} and Spark \cite{shanahan2015large}.

However, cautious usage is required. For example, here are some cases when one \textit{shouldn't} use distributed machine learning: (i) When communication and synchronisation between the distributed parties provides a bottleneck for the computation; (ii) When writing and running a distributed program is too complicated; (iii) When one can run the same algorithm on a multi-core machine. This is possible with smart data sampling, offline
schemes and efficient parallel codes. 

\section{Classical data and machine learning with quantum resources}
There are at least three broad ways in which we can employ quantum resources for classical data over a network: (i) using quantum resources to enhance data processing at individual nodes (ii) using quantum resources to assist in security and/or (iii) using quantum resources to assist in communication.

As we saw in the previous section, machine learning algorithms come in a variety of ways to assist in classical information processing tasks highly applicable in the network setting. In the presence of a classical network, our first question is then whether or not quantum resources can assist in any of the machine learning algorithms that may be relevant in a network setting . These would include tasks related to security. These belong to the class of quantum-enhanced machine learning algorithms.

In the presence of a quantum network with only classical data, a communication complexity advantage is possible \cite{brassard2003quantum}. It is unclear if and how machine learning can be helpful or relevant in this setting. However, there are already some enticing clues \cite{kane2017communication, balcan2012distributed, conitzer2004communication} on the connection between communication complexity and machine learning for classical data over a classical network. We leave questions on the roles that quantum resources can play for future investigation. 

\subsection{Quantum-enhanced machine learning overview}
Quantum-enhanced machine learning algorithms are quantum algorithms performing machine learning tasks. They have so far mostly concentrated on quantum speed-ups with respect to dimensionality of the data involved. \\

\textit{Fully-quantum algorithms---} The first set of these algorithms have chiefly relied on assuming completely quantum devices, keeping coherence throughout the computation and could require full fault-tolerance. For those algorithms claiming up to exponential quantum speedups for supervised algorithms (see \cite{biamonte2017quantum, ciliberto2018quantum}),  the HHL algorithm \cite{harrow2009quantum} for matrix-inversion is often used. However, HHL has a number of drawbacks that make them impractical for near-term quantum devices: (i) the ability to efficiently encode the classical data into quantum states and into quantum memory \cite{aaronson2015read}; (ii) effective read-out of the final quantum state \cite{aaronson2015read}; (iii) generally requiring high circuit-depth and (iv) restrictions on the sparsity and condition numbers of the matrix.

Although later developments have tried to circumvent restrictions on sparsity and focus on low-rank matrices instead (e.g. quantum principal component analysis for low-rank matrices \cite{lloyd2014quantum}), recent work on quantum-inspired classical algorithms have demonstrated efficient classical can exist in these cases \cite{tang2018quantum, gilyen2018quantum, chia2018quantum}. In fact, classical sampling methods developed in \cite{tang2018quantum} for quantum-inspired machine learning algorithms suggest that classical methods for linear algebra problems in low-dimensions (used in machine learning for instance) are likely to find efficient classical algorithms. Although these classical sampling methods are not yet more practical than existing classical sampling methods, they are still more realistic than their quantum counterparts in (i) and (ii).

Another set of approaches, which rely on amplitude amplification and Grover's search algorithms, can give up to quadratic speed-ups. These include and quantum algorithms for reinforcement learning \cite{dunjko2016quantum} and training of quantum perceptrons \cite{kapoor2016quantum}. While theoretically very interesting as long-term goals, near-term proposals are missing.

\textit{Hybrid algorithms---} To find algorithms that may be realised in the the near-term, quantum machine learning algorithms are now giving more attention to hybrid classical-quantum algorithms. These algorithms, which include variational methods for optimisation \cite{moll2018quantum}, have short circuit-depths and where the optimisation process is performed iteratively and classically. They are of roughly two types: one that attempts to enhance classical algorithms with classical input data and another where the quantum advantage lies in efficient quantum state preparation, thus using quantum input data. Prominent examples of the former include quantum approximate optimisation algorithm (QAOA) \cite{farhi2014quantum, farhi2016quantum} and the latter include variational quantum eigensolvers (VQE) \cite{peruzzo2014peruzzo, kandala2017hardware}. We return to VQE in the following section as these solve problems for quantum data.

Both QAOA and VQE can be considered as part of the same framework and their optimisation part (which can be considered only as a component and not the entirety of machine learning) is performed classically. One begins with an ansatz quantum state. An unitary with classically-tunable parameters is then applied to this state and an observable whose expectation value representing the cost function for the problem is subsequently measured. The classical parameters of the unitary are then iteratively tuned until one reaches the lowest value of the cost function (i.e., ground state of a given Hamiltonian), for instance using the classical gradient-descent algorithm. \

In QAOA, the ground state reached then encodes the classical solution to a classical optimisation problem, like MaxCut, and it is a polynomial-time algorithm. Thus, it is not a quantum-enhanced algorithm for a classical machine learning problem, but rather takes advantage of classical machine learning algorithm. It remains to be seen if optimisation problems more directly relevant for networks can be solved in this way.

Alternative frameworks have been developed to find quantum-enhanced algorithms that not only take advantage of classical optimisation algorithms like above, but also to enhance classical machine learning algorithms. These new proposals include quantum circuit learning \cite{mitarai2018quantum}, quantum generalisation of neural networks \cite{wan2017quantum} and Born machines \cite{cheng2018information, benedetti2018generative}. Theoretical demonstration of quantum-enhancements in these settings is still an open problem.

%prepares hard to simulate quantum states. Although not theoretically demonstrating any explicit speed-ups, they may still be useful [Mitarai, Farhi, Gambetta, Oscar]. Also see Zapata1810.10576 and lots of work by Zapata guys [Nana]\\

%\noindent $\bullet$ Also recent work on showing possible advantages of quantum algorithms for generative modelling in machine learning [Ref Alejandro's papers; Zapata guys]. [Chris]\\

%\noindent $\bullet$ Adiabatic methods for quantum machine learning: based on sampling. Here again there is no demonstrated theoretical advantage, but some advantages are shown and discussed \cite{denchev2016computational, li2018quantum}, like quantum-enhanced gibbs sampling. [Chris]

\subsection{Quantum-enhanced machine learning for security and other applications}
\textit{Anomaly detection---} The chief machine learning method for detecting and averting faults and security breaches in classical networks belong to anomaly detection. However, for anomalies in classical data, it appears unlikely that currently available quantum machine learning algorithms can enhance the speed and reliability of detection. One of the primary reasons is the necessity of encoding the classical data into quantum states, which can be very costly \cite{aaronson2015read}. Thus, even if there are quantum-enhanced supervised and unsupervised machine algorithms for anomaly detection in the computational component, the state preparation and read-out demands may be too much. However, the case is different if we begin with quantum data instead and we return to this in section~\ref{sec:sec4}.

\textit{Adversarial quantum machine learning---} Just as machine learning algorithms are vulnerable to attacks, so would quantum-enhanced machine learning algorithms. This is very new area, called adversarial quantum machine learning. Like in adversarial machine learning, the aim is to find more robust quantum machine learning algorithms, and some robust algorithms have been indeed been proposed \cite{wiebe2018hardening}. In addition to finding more robust algorithms, it is also important to understand what the robustness limits of quantum machine learning algorithms actually are, which remains an open problem. A recent result suggests that perhaps just as much quantum resources are necessary for detecting adversaries in higher dimensions as compared to quantum tomography \cite{advql}. Thus it remains unclear the total resource cost of quantum-enhanced machine learning in the presence of adversaries. However, there is a tantalising yet unexplored possibility that perhaps quantum resources can enhance the security of machine learning algorithms, in a similar way that information-theoretic security is afforded to quantum cryptographic protocols.

\textit{Other---} Whether or not there are helpful applications of quantum-enhanced machine learning algorithms to traffic and routing management is currently very unclear and may even appear unlikely. There may be some quantum-enhancements to supervised and unsupervised machine algorithms that could be used in traffic and routing management. However, a key issue still remains in how classical data can be embedded into the relevant quantum states and then read out, in a way that is easier in the quantum setting. The no-cloning theorem forbids reproducing the state and in general overheads in embedding classical information into the relevant quantum states are very high \cite{giovannetti2008quantum, giovannetti2008architectures}. In addition, given the dynamical nature of networks, where machine learning methods appears to be most helpful, the speed of embedding classical data into quantum states must be likewise high. Thus, the necessary quantum resources only to convert classical data to quantum states may overwhelm any computational advantages. 

\subsection{Distributed quantum machine learning}
The reasons to consider distributed quantum machine learning are similar to those for distributed classical machine learning. Suppose one wishes to perform distributed machine learning, either because the given data is naturally distributed or there is limited processing power on any given device. For this purpose, there are existing protocols for implementing general distributed quantum algorithms that could also be helpful in delegating quantum machine learning algorithms, e.g., \cite{beals2013efficient}.

Secure delegated quantum computational protocols in \cite{joe} can also be modified to be applied to the quantum machine learning context \cite{sheng2017distributed, bang2015protocol}. However, here the same problem with state preparation could exist, for the server and not for the client. Alternatively, hybrid-classical quantum algorithms for distributed quantum machine learning have been developed in \cite{yoo2014quantum}. Here the quantum state preparation assumptions can be obviated by using a hybrid gate that takes in classical input data and performs unitary operations controlled by the classical values instead of a quantum control-gate.
\section{Quantum data and machine learning} \label{sec:sec4}
Suppose the data we are give are naturally quantum in the form of quantum states or channels: this is quantum data. This means we are not necessarily given their classical descriptions to begin with. We can also be restricted on the number of copies we have access to due to the no-cloning theorem.

In these cases, it is found that classical machine learning methods may be helpful over traditional methods in dealing with quantum data. Another approach is to use quantum protocols to directly process quantum data. Learning protocols in the latter case belong to the field of quantum learning.

It is possible to process quantum data over either a classical or a quantum network. Techniques from classical machine learning methods for quantum data may assist in the communication of quantum data over a classical network while quantum learning protocols may be more appropriate over a quantum network. We are at the very beginning of this area of investigation. It is yet unclear exactly if and how these methods may be applicable and these serve as tantalizing inspiration for future study.

\subsection{Classical machine learning for quantum data}
\textit{Tomography---} Suppose data come naturally in the form of a quantum state or a quantum channel. Then for classical processing of this data over a classical network, the first task is to find its classical description. The canonical methods for this are quantum state tomography and quantum process tomography. However, due to the no-cloning and the cost of quantum measurements, tomography is in general very resource intensive, requiring the number of copies of the quantum states to scale exponentially with the number of qubits per state. However, recent work have revealed methods on efficient state tomography using classical machine learning techniques \cite{Torlai2017, Han2017} over a larger range of states than previously studied.

\textit{Separability---} While tomography reveals the complete classical description of the quantum data, sometimes it may be sufficient to first classify the data in terms of their quantum properties. For instance, methods for classifying quantum states directly in terms of separability have been devised using classical machine learning \cite{Ma2017, Su2017, Gao2018}. Here there are empirical demonstrations of some advantages compared to the CHSH inequality. However, gathering sufficient training states might still remain a problem for states of higher dimensionality.

\textit{Automated experiment design---} In a future quantum internet with entangled quantum networks, it is desirable to find the optimal methods of creating the types and extent of entanglement required with respect to resource constraints. It is also desirable this process may be automated. Recently, such automated methods based on classical reinforcement learning \cite{alexey} have been proposed, to experimentally create a variety of entangled states with more efficiency. This provides an exciting beginning for automated design of future quantum internet protocols. 

\textit{VQE---} We saw that variational quantum eigensolvers rely on classical optimisation. When used with input quantum data, they have found success mostly in quantum chemistry \cite{peruzzo2014peruzzo, moll2018quantum}. In the context of quantum networks on the other hand, the most relevant work so far may be its use in quantum data compression \cite{jonromero} which may aid the communication of quantum data over a network. 
%\noindent $\bullet$ Phases of matter for quantum systems processed using machine learning \cite{Juan2017,Torlai2017,Huber2017}. 

\subsection{Quantum learning protocols}
\textit{Template matching---} The first quantum algorithms for quantum data most relevant for machine learning are quantum template matching algorithms \cite{saski1, sasaki2}. These are classification algorithms, where each class is represented by a quantum state: a `template'. The task is to find the class to which a given test quantum state belongs, where this state is not identical to any of the template states. It is not clear on its own whether quantum template matching is directly useful in a quantum network setting. However, the ideas introduced here provide the key foundation for supervised learning of quantum data, which can be used in the quantum counterparts to supervised algorithms in traffic prediction, classification and anomaly detection.

\textit{Learning quantum processes---} Suppose one wants to send just enough information about a quantum process over a quantum network in order for the other parties to replicate the use of this process onto any desired quantum state. In the quantum data scenario, one is not a priori given the classical description of this quantum process. Instead, one is provided only a finite number of queries of this quantum process. For a unitary operation, this problem is tackled in \cite{bisio_optimal_2010}, in a problem called the quantum learning of unitary operations. A very interesting observation made here is that the optimal strategy is semi-classical instead of fully-quantum: meaning that it is sufficient for the classical data encoding the estimation of the unknown unitary to be stored. It remains an open question on how these results may change if one extends to more general quantum processes.

\textit{Quantum learning and security---} In a future quantum network with quantum data being exchanged between different parties, it becomes important to detect unusual behaviour in the incoming quantum data. These may be the first signs of a security breach or a fault in the network. For dynamical data in a time-series, for instance, change point detection addresses precisely this problem. This has been extended to the quantum domain \cite{gael1,gael2} where the optimal methods for detecting a change in quantum data are found using methods from state discrimination. For static data, anomaly detection methods based on machine learning become more appropriate as the definition of of unusual behaviour is based on priori training data. Classical anomaly detection algorithms have been applied to quantum data in \cite{sara} for the purpose of error detection, in the case where the classical description for the quantum data is known. However, for cases where the classical description for the quantum data is unknown (as expected over a quantum internet), it is instead much more efficient to directly apply quantum algorithms onto the quantum data directly. Examples of this include several quantum algorithms for anomaly detection was proposed in \cite{liu2018quantum}.

%See Chris' email: Seems we should take a look at this! https://www.nature.com/articles/npjqi201619\\

%\noindent $\bullet$ Existing quantum learning algorithms are very few, restricted to quantum template matching algorithms, quantum change point problem and quantum anomaly detection. The benefit of directly quantum algorithms coming from obviating the need for tomographic resources. Briefly mention possibilities about applications to security, traffic, routing and resource management, not with its own section since very little work done on this. Cite Gael's new paper as well as Marco's. 
%\section{Outlook}
%Communication complexity benefits for distributed quantum machine learning algorithms? 



%\appendix 
%\section{Appendix}
%There are two classes of applications at the intersection of classical machine learning and classical networks: 
%\begin{enumerate}
%\item Given we want to use machine learning for an application, how can a network structure assist? 
%\item Given we have a network setting, how can machine learning methods help to solve problems arising in this setting? 
%\end{enumerate}
%For the first class of applications, we have two basic scenarios. The first is when the data required for our machine learning algorithm naturally originate from different locations and thus a network infrastructure is necessary to distribute the data to a centralised processor. The second scenario is when one has big data, so one requires decentralised memory and distributed computation to perform the relevant machine learning algorithms. For instance, see survey of methods for classical distributed learning \cite{peteiro2013survey}. Also secure distribution of data for machine learning \cite{mirhoseini2016cryptoml}. Also distributed learning in sensor networks \cite{predd2005distributed}. \\

%In the second class of applications, machine learning plays a prominent role in some cybersecurity applications like network anomaly detection \cite{ahmed2007machine}, \cite{fraley2017promise}, \cite{joseph2013machine}(including review of datasets \cite{yavanoglu2017review}). Applications of machine learning to network intrusion detection though has been criticized \cite{sommer2010outside}. Machine learning may also be important for other aspects of networks \cite{boutaba2018comprehensive}, \cite{wang2018machine}, \cite{mestres2017knowledge}, network traffic control systems \cite{fadlullah2017state}, but work here is still in its infancy and there is debate on the real effectiveness of machine learning techniques in these settings. Also there is machine learning applied to the internet of things \cite{mahdavinejad2017machine}. An ultimate goal would be towards fully automated networks. \\

%Networking problems can be formulated as one of these problems that can leverage ML. For example, a classification problem in networking can be formulated to predict the kind of security attack: Denial-of-Service (DoS), User-to-Root (U2R), Root-to-Local (R2L), or probing, given network conditions. Whereas, a regression problem can be formulated to predict of when a future failure will transpire.\\

%\textbf{Distributed machine learning}\\
%See \cite{peteiro2013survey}

%\textbf{Network security}\\

%\textbf{Traffic engineering}\\ Traffic prediction (as a time-series forecasting problem and also as non-TSF). Mostly uses supervised NN; traffic classification; traffic routing (reinforcement learning is used here) 

%\textbf{Network performance optimisation}
%\section{Quantum machine learning and classical networks}
%Individual quantum machine learning algorithms with speed-ups and only classical transmission of data (e.g. classical data sent to centres which then create quantum state resources). Give a few names of algorithms with speed-ups and include names of reviews. \\

%The second part are quantum algorithms which might help with classical network problems (e.g. classical routing...etc). Also may help with cybersecurity (e.g. quantum anomaly detection).

%\section{Classical machine learning and quantum networks}

%Name if there are any advantages in using classical machine learning for quantum network problems. Mention that other classical (not necessary ML) methods used to simulate quantum networks(e.g. add SimulaQron). \\

%Not sure if there are definite advantages, but there are lots of classical problems associated with the design and working of a quantum network: minimizing cost function in architecture design, tomography of states, channels and other error characterisation, QTCP protocol has many classical subproblems, protecting quantum memory requires error correction.\\


%Quantum networks can help with classical machine learning? (Tensor network stuff? Data security?) 

%\section{Quantum machine learning in a quantum network}

%Here there are many classes of problems that are analogous to problems where classical machine learning appears in classical network settings. These separate into cases where for machine learning applications one needs a quantum network for distributed settings and cybersecurity. Another class of applications include where quantum machine learning algorithms are used to solve problems in a quantum network, like traffic engineering and  network optimisation. 

%\subsection{Distributed quantum machine learning}

%General results in distributed quantum computation (e.g. Eisert et al; Beals et al \cite{beals2013efficient}). \\

%Also classes of joint function computation where communication complexity can be reduced with quantum communication, but no quantum machine learning example yet (except maybe quantum fingerprinting as a primitive example: since a swap test can be interpreted as a classifier say in quantum anomaly detection), so perhaps another motivation to use the distributed setting. \\

%Also mention the works of JB and other Korean groups. \\
%\subsection{Quantum network security}
%Anomaly detection...etc (also quantum change point as related problem)\\


%\subsection{Quantum traffic engineering}
%\subsection{Quantum network performance optimisation} 
%\section{Outlook}
%Emergent intelligent properties of quantum networks and fully automated, self-configuring  quantum networks...
\clearpage
\begin{table}[h]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{llll}
Data/Network & Classical & Quantum \\\hline
Classical & Current internet (CC) & Classical data in quantum network (CQ) \\
Quantum & Quantum data in classical network (QC) & Fully quantum internet (QQ)
\end{tabular}
\end{adjustbox}
\caption{\label{tab:CommTable} Classical and quantum data in a network}
\end{table}
\clearpage 

\begin{table}[h]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lllp{5cm}}
Network  & Classical data & Quantum resources  & Quantum data \\
concerns & & and classical data & \\\hhline{|=|=|=|=|}
Individual & Classical   & Quantum-enhanced  & Quantum learning  \\ 
computing & machine learning & machine learning \\ \hline 
Security and faults & Machine learning for anomalies  & Adversarial quantum & Anomaly detection and  \\
& and faults: detection and prediction; & machine learning  & change point detection \\
& Adversarial machine learning &  & for quantum data \\ \hline 
Routing and traffic & Machine learning for \\
& traffic prediction, classification, & Open problems  & Open problems \\
& congestion control and routing\\ \hline 
Distributed  & Distributed machine learning & Distributed quantum & Distributed quantum learning \\
computing & & machine learning\\ \hline 
 Communication & Data compression & Open problems & Data compression and \\
 & and machine learning & & quantum machine learning \\ \hline 
\end{tabular}
\end{adjustbox}
\caption{\label{tab:CommTable2} \textit{Classical and quantum machine learning applications in classical and quantum networks.} Almost all of the categories here are very new and open to exploration in the quantum domain.}
\end{table}

\bibliography{sample}

\end{document}