%
% Optimising the World
%

\section{Optimising the world}\label{sec:optimising_the_world}\index{Optimisation}

Every aspect of our modern world is heavily optimised to improve efficiency, affordability, profitability, or any other kind of desirability. Even long before the digital revolution, which enabled the widespread implementation of modern optimisation-theoretic techniques, humans have always striven to make life as easy as possible -- the least effort for the greatest possible reward. Our modern application of optimisation theory is merely a logical extension of this to the many other facets of the 21st century economy that now exist.

\subsection{Optimisation in everyday life}

Broadly speaking, optimisation problems can all in some sense be thought of as \textit{resource allocation} problems\index{Resource allocation} -- given finite resources, that we would like to utilise most efficiently, what is the best way to allocate and distribute them within a complex system?

To lay the context for the remainder of the section, and illustrate the importance and transformative potential for improved optimisation approaches, we summarise some of the key everyday applications for optimisation theory that we all rely on, usually unwittingly, executed somewhere in the background in the cloud, the end user being oblivious to the gargantuan calculations being performed behind the scenes merely to update a barely noticeable on-screen logo.

\subsubsection{Traffic networks}\index{Traffic networks}

Given our highly complex road networks, what is the best route to take to get home, given the highly complex and often unpredictable dynamics of road traffic? And how do our optimisation approaches change with potentially millions of travellers simultaneously competing to minimise travel time?

In such multi-user systems, with so many users, {\sc Greedy}\index{Greedy strategy} strategies, based on optimising users individually are highly sub-optimal, and globally optimised algorithms must be pursued. For example, if there are a thousand drivers competing to get from Town Hall to Redfern, it makes no sense to optimise them individually, since then they will all be identically directed down George St, which will of course quickly saturate and congest. Obviously load-balancing across the various routes benefits everyone collectively \textit{and} individually.

In the case of the discredited, but straightforward {\sc Greedy} strategy, a simple application of Dijkstra's shortest path algorithm (Sec.~\ref{sec:shortest_path}) will yield the optimal route for an individual user, and very quickly since Dijkstra's algorithm has only $O(n^2)$ complexity (i.e a \textbf{P} algorithm).

However, the complexities of a global multi-user optimisation are intuitively evident -- with countless competing interests, finding a set of routes that minimises net transit time yields an enormous space of possibilities and variations to consider. Dijkstra's tempting algorithm is no longer applicable, and we must employ harder algorithms, many of which are \textbf{NP}-complete.

\subsubsection{Public transport scheduling}\index{Public transport scheduling}

Given a fixed network of train lines, and a fixed number of trains, but the ability to schedule them freely, how does one schedule a roster that minimises average waiting times?

This might seem straightforward in simple test-cases. As before, optimising a single route, or several independent routes is trivial. But once complex, conflicting interdependencies are in place, conflict resolution becomes impossible to eliminate. Scheduling the Epping train to leave 5 minutes earlier will allow its passengers to catch the 5pm Hornsby train. But by leaving those few minutes earlier, passengers arriving from the Blue Mountains train will miss their connection and have to wait for the next train.

We are once again in a situation where we are overwhelmed with exponentially growing combinatorics to try and minimise the countless possible schedule conflicts that can occur. 

The importance of this optimisation problem is of obvious importance. Minimising the resources required to operate public transport effectively could save enormous amounts of money from state budgets. Not to mention, passenger waiting time is of value too. If a million passengers lose just a few minutes of productivity per day to increased commute times, this can amount to billions of dollars a year in lost productivity to the broader economy.

\comment{To do}

\subsubsection{Economics}\index{Economics}

\comment{To do}

\subsubsection{Supply chain networks}\index{Supply chain networks}

The modern economic infrastructure for the production and distribution of goods is built upon supply chains -- complex, interdependent networks of the exchange of resources between entities as goods pass through their many stages of production before reaching the consumer. Each exchange of resources will typically be subject to its own constraints, such as strict time of arrival demands. Effectively this yields a massive instance of a complex satisfiability problem, where all, or as many as possible of the demands of the units in the chain must be simultaneously met.

It is well known that the most complex such satisfiability problems are \textbf{NP}-complete\index{\textbf{NP}-complete} with no known efficient classical solutions (in fact even very trivial constructions of satisfiability problems are already \textbf{NP}-complete, see Fig.~\ref{fig:3SAT}).

Bearing in mind that modern supply chains may be dealing with billions of dollars in resources at any given time, even minor improvements to their optimisation could be of enormous monetary value. 

\comment{More???}

\subsection{The difficulty of optimisation problems}\index{Difficulty of optimisation problems}

\comment{To do}

\subsection{Classical optimisation techniques}\index{Classical optimisation techniques}

\subsection{Quantum-enhanced optimisation}

\subsubsection{Satisfiability \& \textbf{NP}-complete problems}\index{Satisfiability problems}\index{\textbf{NP}-complete}

Many readers will have heard of the \textit{travelling salesman problem}\index{Travelling salesman problem}, the task of finding the shortest route through a weighted graph that traverses every vertex. This task is known to be \textbf{NP}-complete.

Many other algorithms are also known to be \textbf{NP}-complete, a number of which that are relevant to networking are discussed in detail in Sec.~\ref{sec:graph_theory}, summarised in Table.~\ref{tab:net_alg_sum}.

Such \textbf{NP}-complete algorithms can be quadratically enhanced in runtime using Grover's algorithm. To see this, note that all \textbf{NP}-complete problems can be efficiently mapped to one another with polynomial resource overhead (see Fig.~\ref{fig:complexity_classes}). Thus, we can restrict ourselves to considering the satisfiability problems\index{Satisfiability problems} discussed above -- the archetypal \textbf{NP}-complete problems. An example of the 3-\textsc{SAT} problem\index{3-SAT problem}, which is \textbf{NP}-complete, is shown in Fig.~\ref{fig:3SAT}.

\begin{figure}[!htb]
\includegraphics[width=0.3\textwidth]{3SAT}
\caption{Digital circuit for an instance of the 3-\textsc{SAT} problem, with 4 clauses acting on input variables $\{x_i\}$. Each of the OR gates is input with some combination of 3 of the input bits or their compliments (i.e with a NOT gate). Each of these is referred to as a `clause', of which there are 4 in this example, but could be any number in general. The final AND gate requires that all clauses be simultaneously satisfied in order to yield a final output of `1'. The goal of the problem is to find an input bit-string $x$ that yields an output of `1'. In general, this may require exhaustively searching over the entire space of input states via brute-force, which exhibits time-complexity exponential in the length of the bit-string. This problem is proven to be \textbf{NP}-complete. Note that the similarly-defined 2-\textsc{SAT}\index{2-SAT problem} problem (i.e clauses each contain 2 input bits) is \textbf{P}, making 3-\textsc{SAT} the simplest model to consider in the study of \textbf{NP}-complete problems.} \label{fig:3SAT}	
\end{figure}

Now, by defining an oracle that implements a polynomial-time algorithm on $n$ qubits, a Grover search over the input space of $2^n$ configurations will determine the satisfying input to the oracle for a given desired output, which acts as the tagged element within the search algorithm. The Grover search yields a quadratic speedup for this search compared to a brute-force classical search, therefore requiring only $O(2^{n/2})$ oracle calls. While this is short of the exponential speedup one might hope for, a quadratic speedup can nonetheless be very significant for large instances of the problems.

\subsubsection{Approximating optimisations as satisfiability problems}\index{Approximating optimisation problems}

Some problems in even harder classes than \textbf{NP}-complete can in some instances be \textit{approximated} using the same approach. The key to solving such problems is to define an oracle that attributes a \textit{score} to a given input, rather than a yes/no answer to satisfiability, and answers `yes' or `no' depending on whether that score is above some defined threshold. As an illustrative example, consider the optimisation of, say, a complex traffic network, where the goal is to maximise flow through the network. Then we might define our score to be some flow metric for the network's graph.

We then apply a Grover search repeatedly, each time incrementing this threshold until the algorithm outputs `no'. Then we know that the last input had the highest score. The reason this approach is \textit{approximate} rather than \textit{exact} is that defining such a score-oracle mightn't be always efficiently implemented, or maybe it mightn't make sense at all to define score measures for a given problem.

\comment{To do}

\comment{\textbf{BQP} optimisation problems}