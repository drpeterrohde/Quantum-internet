%
% The QuantumMind - Quantum Machine Learning
%

\section{The Quantum Mind\texttrademark\,-- Quantum machine learning}\label{sec:quantum_mind}\index{Quantum machine learning}\index{Machine learning}

\famousquote{If computers get too powerful, we can organise them into committees. That'll do them in.}{Unknown}
\newline

\famousquote{My unshakeable belief in the stupidity of the animal man has never disappointed me and has often helped me throughout my life.}{Arthur Schopenhauer}

\sectionby{Nana Liu}
  
\comment{Tidying, editing, proofing, structure. Section titles.}\\

\dropcap{I}{n} recent years, the implementation of artificial intelligence via machine learning techniques has become a forefront area of research, transforming many software industries and those that depend upon them. An obvious question to ask is to what extent machine learning techniques translate across to the quantum computing environment, and whether upon doing so there is an associated quantum enhancement. While this field of \textit{quantum machine learning} (QML) is far too extensive to summarise here, we will instead present a brief overview of how machine learning might apply in a networked quantum environment.

There are two distinct avenues to consider here. First, how does machine learning influence the operation of quantum networks? Second, how do quantum networks affect the implementation of machine learning? We will outline some of the key considerations here from both these opposing angles of consideration.

\subsection{Overview}

Today, classical machine learning is affecting the understanding and better regulation of the classical networking infrastructure underpinning the modern internet. This includes network pattern recognition, security and fault management, routing and traffic management, resource management, and distributed computation. In these applications, it may not solely be processing power that is of importance, but additionally reliability and security may also be paramount.

The large intersection between machine learning and network systems is perhaps unsurprising. Firstly, machine learning relies on access to data, and in many real-world scenarios, data naturally emerges from distributed sources. Secondly, especially for complex systems like large networks, the information to process is complex, containing many uncertainties, and subject to errors. Exactly solvable models in these regimes are rare, a scenario where estimation techniques based on machine learning are often helpful.

In the coming quantum era we can envision three distinct ways where quantum resources might be introduced: quantum communication; quantum processing at individual nodes; and, data that is inherently quantum in nature. To begin, we first make a classification of the four foreseeable network types (summarised in Tab.~\ref{tab:CommTable}). These can be classified as:

\begin{itemize}
\item CC: classical data and processing over a classical network (e.g the present-day internet).
\item CQ: classical data and processing over a quantum network.
\item QC: quantum data and processing over a classical network.
\item QQ: quantum data and processing over a quantum network -- a fully-quantum internet.
\end{itemize}

\startnormtable
\begin{table*}[htbp!]
\begin{tabular}{|l|l|l|l|}
\hline
Data/Network & Classical & Quantum \\
\hline
\hline
Classical & Current internet (CC) & Classical data in quantum network (CQ) \\
Quantum & Quantum data in classical network (QC) & Fully quantum internet (QQ)\\
\hline
\end{tabular}
\captionspacetab \caption{\label{tab:CommTable}Classical and quantum data in a network.}
\end{table*}

Now the inevitable question arises: how do these different scenarios relate to machine learning?

This is not yet an active research area in its own right. However, there are some preliminary toolkits that are starting to be developed in the new field of QML. By first summarising the intersection between the classical internet and classical machine learning, we gain insight into the kinds of tools required to start examining their quantum counterparts. For instance, we will see how aspects of quantum processing of quantum data might be aided by machine learning, how machine learning may be enhanced by quantum resources, and how machine learning may be implemented in these distributed quantum settings. A summary is presented in Tab.~\ref{tab:CommTable2}. 

\begin{table*}[htbp!]
\begin{tabular}{|l|l|l|l|}
\hline
Network  & Classical data & Quantum resources  & Quantum data \\
concerns & & and classical data & \\
\hline
\hline
Individual & Classical   & Quantum-enhanced  & Quantum learning  \\ 
computing & machine learning & machine learning & \\
\hline 
Security and faults & Machine learning for anomalies & Adversarial quantum & Anomaly detection and  \\
& and faults: detection and prediction; & machine learning  & change point detection \\
& Adversarial machine learning &  & for quantum data \\
\hline 
Routing and traffic & Machine learning for  & Open problems & Open problems \\
& traffic prediction, classification, &   &  \\
& congestion control and routing & & \\
\hline 
Distributed  & Distributed machine learning & Distributed quantum & Distributed quantum learning \\
computing & & machine learning & \\
\hline 
 Communication & Data compression & Open problems & Data compression and \\
 & and machine learning & & quantum machine learning \\
\hline 
\end{tabular}
\captionspacetab \caption{\label{tab:CommTable2} Classical and quantum machine learning applications in classical and quantum networks. Almost all of the categories here are very new and open to exploration in the quantum domain.}
\end{table*}
\startalgtable

\subsection{Classical machine learning in classical networks}\index{Classical machine learning!Classical networks}

To create and maintain efficient classical networks, one requires efficient and reliable processing at individual nodes, security, efficient routing and data transmission, efficient use of resources, and a means for distributed processing \cite{bib:boutaba2018comprehensive, bib:wang2018machine}. We now present a brief overview of how machine learning techniques apply in these areas. 

\subsubsection{Machine learning basics}

Machine learning algorithms allow us to make predictions about a current or future dataset without requiring explicit instruction on how to do so. Since the aim is directed more towards \textit{prediction}\index{Prediction} than purely \textit{estimation}\index{Estimation}, it differs from the field of statistical estimation\index{Statistical estimation}, although they share many techniques.

There are three main paradigms for machine learning:
\begin{itemize}
	\item Supervised learning\index{Supervised learning}: relies upon training data\index{Training data} from which inferences and predictions about new test data can be extracted.
	\item Unsupervised learning\index{Unsupervised learning}: makes inferences from the data at hand without training.
	\item Reinforcement learning\index{Reinforcement learning}: operates using a different framework, and aims to find the best action to take to maximise a given reward in a particular environment.
\end{itemize}

Machine learning is used regularly for data collection, feature engineering, and model learning. There are many excellent introductory texts on this topic \cite{bib:bishop2006pattern, bib:shalev2014understanding, bib:trevor2009elements, bib:marsland2011machine, bib:flach2012machine}.

\subsubsection{Security \& fault management}\index{Security}\index{Fault management}

There are two primary ways in which machine learning applies to managing security and faults in networks. The first is \textit{using} machine learning techniques to predict and detect security breaches and faults in the network, including anomaly detection. The second is in studying the security vulnerabilities of machine learning algorithms themselves, as the presence of adversaries is natural in real-world networks -- so-called `adversarial machine learning'\index{Adversarial machine learning}.

\paragraph{Anomaly detection \& fault management}\index{Anomaly detection}\index{Fault management}

When there are security breaches in a classical network, one desires the ability to predict and detect them, as well as a method for making protocols more robust against them. Machine learning is often used in anomaly and intrusion detection. These algorithms seek out unusual data or changes within it.

Broadly, there are three classes of anomalies: point, contextual, and collective, which refer respectively to single datum anomalies, unusual data with respect to a specified context, and clusters of data which suggest unusual behaviour. Both supervised and unsupervised algorithms are employed in these settings \cite{bib:thottan2003anomaly, bib:ahmed2007machine}. One of the prime challenges here is determining the presence of anomalies when limited data is available, and the associated rates of false identifications.

Fault management in a network is also extremely relevant, especially for complex networks more exposed to errors. We desire the prediction, detection and localisation of faults. Most applicable machine learning methods here employ supervised algorithms. However, the paucity of real training data (as opposed to synthetic data generated via simulation) means that algorithms might be poorly trained, especially in newly established networks \cite{bib:hood1997proactive, bib:kogeda2006prediction, bib:snow2005assessing}. This is to be reasonably anticipated with the deployment of a future quantum internet. To accommodate for this, new methods have arisen where unsupervised machine learning techniques are used instead to detect changes in the network rather than relying on labelled fault data \cite{bib:hajji2005statistical}.

In particular, to identify and localise unusual network behaviour, either due to natural faults or adversaries, network anomaly detection methods can be employed \cite{bib:ahmed2007machine, bib:fraley2017promise, bib:joseph2013machine}. Since results can be sensitive to the employed training data, it is important to examine which datasets are most appropriate for a given application \cite{bib:yavanoglu2017review}. Particularly, there have been many proposals for utilising anomaly detection in network intrusion. However, this approach has been criticised for its use in real-world scenarios, where it's often difficult to distinguish anomalies related to intrusions from those attributed to other factors, and the complexity of real-world networks may make it too difficult to define what even constitutes a `normal' signal \cite{bib:sommer2010outside}.

\paragraph{Adversarial machine learning}\index{Adversarial machine learning}

Machine learning algorithms themselves exhibit security vulnerabilities \cite{bib:huang2011adversarial}. There are two main types of attacks to which they are vulnerable:
\begin{itemize}
\item Evasion\index{Evasion}: directed at the test data.
\item Poisoning\index{Poisoning}: directed at the training data and machine learning models.
\end{itemize}

In real-world scenarios, data often originates from different sources, making adversarial attacks more likely. It has been discovered that many machine learning algorithms are in fact vulnerable to adversarial attacks, the first discovered in \cite{bib:szegedy2013intriguing}. A large proportion of the literature focuses on the details of specific algorithms: the detection of adversaries; their different methods of attack; and, the particular defences against them \cite{bib:kurakin2018adversarial}. However, recently, more foundational work has emerged, explaining the origins of this vulnerability as arising from the high dimensionality of the underlying data \cite{bib:goodfellow2014explaining, bib:gilmer2018adversarial, bib:mahloujifar2018curse}.

\subsubsection{Traffic management \& routing }\index{Traffic management}\index{Routing}\index{Congestion control}

The effective operation of large-scale networks requires automated management protocols. This includes efficient means for traffic prediction, traffic classification, routing, and congestion control\index{Congestion control}. Machine learning algorithms have been developed for all of these.

Predicting network traffic is becoming increasingly important, especially in diverse and complex networks. This is commonly addressed using time-series forecasting\index{Time-series forecasting} (TSF) methods. This can make use of either statistical analysis techniques, or supervised machine learning methods \cite{bib:bermolen2009support, bib:chabaa2010identification, bib:cortez2006internet}. Non-TSF methods also exist \cite{bib:chen2016predicting, bib:li2016inter}.

The most commonly used technique for traffic classification is the so-called flow feature-based technique\index{Flow feature}. This takes into account information about unidirectional packet transmissions. Here, supervised machine learning techniques have been found to be accurate. However, unsupervised techniques have been found to be more robust. Their joint application is a very powerful tool \cite{bib:erman2007offline, bib:zhang2015robust}.

Machine learning is most applicable to dynamic routing problems, requiring rapid updating of optimal routes. Since such settings require frequent reevaluation, reinforcement learning algorithms are most appropriate. In particular, Q-learning\index{Q-learning} has performed well in various networks \cite{bib:wang2006adaptive, bib:forster2007froms, arroyo2007q}.

Network congestion control is important to ensure stability and the minimisation of packet loss. Well-known congestion control methods like queue management already exist. However, machine learning can be used to enhance the effectiveness of congestion control in various scenarios, especially for packet-based TCP/IP networks \cite{bib:liu2002end, bib:barman2004model, bib:el2005improving}. 

\subsubsection{Distributed machine learning}\index{Distributed machine learning}

Distributed machine learning is simply the fusion of distributed computation with machine learning, where the learning algorithm is distributed across a network. This becomes highly relevant in several notable scenarios:
\begin{itemize}
\item Training and/or testing data originates from different sources. This is the naturally distributed setting.
\item There is too much data to store locally on a single device.
\item When fault-tolerance becomes important (e.g for high-value data), decentralised storage provides enhanced data integrity.
\end{itemize}

The toolbox and infrastructure for distributed machine learning is rapidly developing, and there are many known algorithms \cite{bib:peteiro2013survey, bib:florian2013}. Existing platforms catering for distributed machine learning include MLbase\index{MLbase} \cite{bib:MLbase}, Hadoop\index{Hadoop} \cite{bib:white2012hadoop}, and Spark\index{Spark} \cite{bib:shanahan2015large}.

Caution is required, however, as there are cases when one \textit{shouldn't} employ distributed machine learning, such as when:
\begin{itemize}
\item Communication and synchronisation between distributed parties presents a bottleneck for computation.
\item Developing and executing distributed software is too complicated.
\item One can run the same algorithm on a multi-core machine. This is possible with smart data-sampling, offline schemes, and efficient parallel codes.
\end{itemize}

\subsection{Machine learning on classical data with quantum resources}

There are at least three broad ways in which we can employ quantum resources for classical data over a network, specifically they:
\begin{itemize}
\item Enhance data-processing at individual nodes.
\item Improve security.
\item Enhance communication.
\end{itemize}

In a classical network, the first question is whether or not quantum resources can assist in any of the relevant algorithms. These belong to the class of quantum-enhanced machine learning algorithms.

In a quantum network with only classical data, communication complexity\index{Communication complexity} improvements are possible \cite{bib:brassard2003quantum}. It's unclear whether machine learning has utility in this setting, although there are some promising hints in this direction \cite{bib:kane2017communication, bib:balcan2012distributed, bib:conitzer2004communication}.

\subsubsection{Quantum machine learning overview}\index{Quantum machine learning}

Quantum(-enhanced) machine learning (QML) algorithms are quantum algorithms performing machine learning tasks, exhibiting super-classical enhancements. They have so far mostly concentrated on quantum speed-ups with respect to the dimensionality of the underlying data.

\paragraph{Fully-quantum algorithms}

The first of these algorithms relied on fully quantum devices, maintaining coherence throughout computation, requiring full fault-tolerance\index{Fault-tolerance}. For supervised learning algorithms claiming exponential quantum enhancement \cite{bib:biamonte2017quantum, bib:ciliberto2018quantum}, the HHL algorithm \cite{bib:harrow2009quantum}\index{HHL algorithm} for matrix inversion\index{Matrix inversion} is often employed. However, HHL exhibits a number of shortcomings, making it impractical for near-term quantum devices:
\begin{itemize}
\item The ability to efficiently encode classical data into quantum states and memory \cite{bib:aaronson2015read}.
\item Effective quantum state read-out \cite{bib:aaronson2015read}.
\item They generally require high circuit-depth.
\item There are restrictions on the sparsity and conditioning of the matrices to which the algorithm is applied.
\end{itemize}

Although subsequent developments have attempted to circumvent sparsity restrictions, and rather focus on low-rank matrices (e.g quantum principal component analysis for low-rank matrices \cite{bib:lloyd2014quantum}), recent work on quantum-inspired classical algorithms\index{Quantum-inspired classical algorithms} has demonstrated that previously undiscovered, efficient classical algorithms can exist \cite{bib:tang2018quantum, bib:gilyen2018quantum, bib:chia2018quantum}. In fact, classical sampling methods \cite{bib:tang2018quantum} for quantum-inspired machine learning algorithms suggest that classical methods for linear algebra problems in low-dimensions are likely to have efficient classical algorithms. Although these classical sampling methods are not yet more practical than existing classical sampling methods, they are still more practical than their quantum counterparts.

Another set of approaches, relying on amplitude amplification\index{Amplitude amplification} and Grover's search algorithm\index{Grover's algorithm}, can provide up to quadratic runtime enhancement. These include quantum algorithms for reinforcement learning \cite{bib:dunjko2016quantum}, and training of quantum perceptrons \cite{bib:kapoor2016quantum}\index{Perceptrons}. While theoretically appealing as long-term objectives, viable near-term proposals are absent.

\paragraph{Hybrid algorithms}\index{Hybrid algorithms}

To find algorithms practically viable in the the near future, research is increasingly devoting its attention to hybrid classical-quantum algorithms. These algorithms, which include variational methods for optimisation \cite{bib:moll2018quantum}, exhibit low circuit-depth, where the optimisation process is performed iteratively and classically. There are roughly two varieties: one that attempts to enhance classical algorithms with classical input data; and another where the quantum advantage lies in efficient quantum state preparation, thus relying on quantum input data. Prominent examples of the former include quantum approximate optimisation algorithms\index{Quantum approximate optimisation algorithms} (QAOA) \cite{bib:farhi2014quantum, bib:farhi2016quantum}, and the latter includes variational quantum eigensolvers (VQE) \cite{bib:peruzzo2014peruzzo, bib:kandala2017hardware}, which we return to in the subsequent section.

Both QAOA and VQE can be considered as belonging to the same broader framework, and their optimisation component (which may be considered only as a component, not the entirety of machine learning) is performed classically. One begins with an ansatz quantum state. A unitary operation with classically-tuneable parameters is then applied to this state, and an observable whose expectation value represents the problem's cost function\index{Cost function} is subsequently measured. The classical parameters of the unitary are then iteratively adjusted until cost function minimum is reached (i.e a Hamiltonian ground state), for instance using the classical gradient-descent algorithm\index{Gradient-descent algorithm}.

In QAOA, the respective ground state encodes the classical solution to a classical optimisation problem, like \textsc{MaxCut}\index{MaxCut}, exhibiting efficient polynomial runtime. Thus, it is not a quantum-enhanced algorithm for a classical machine learning problem, but rather exploits a classical machine learning algorithm. It remains to be seen if optimisation problems more directly relevant to networking applications can be solved in this way.

Alternate frameworks have been developed to find quantum-enhanced algorithms that not only take advantage of classical optimisation algorithms, but also enhance classical machine learning algorithms. These new proposals include quantum circuit learning \cite{bib:mitarai2018quantum}\index{Quantum circuit learning}, quantum generalisations of neural networks \cite{wan2017quantum}\index{Quantum neural networks}, and Born machines \cite{bib:cheng2018information, bib:benedetti2018generative}\index{Born machines}. Theoretical demonstration of quantum enhancement in such settings remains an important open problem.

\subsubsection{Security \& other applications}\index{Security}

\paragraph{Anomaly detection}\index{Anomaly detection}

The chief machine learning method for detecting and averting faults and security breaches in classical networks is in anomaly detection. However, for anomalies in classical data, it appears unlikely that currently available QML algorithms can enhance detection speed or reliability. One of the primary reasons is the necessity for encoding classical data into quantum states, which can be very costly \cite{bib:aaronson2015read}. Thus, even if there are QML algorithms for anomaly detection in the computational stage of processing, state preparation and readout overheads may be prohibitive. However, this is no longer the case if we instead begin with quantum data, to be discussed in Sec.~\ref{sec:ml_quantum_data}.

\paragraph{Adversarial quantum machine learning}\index{Adversarial machine learning!Quantum}

Just as classical machine learning algorithms are vulnerable to attacks, so is QML. This is a very new field, known as \textit{adversarial QML}. As with adversarial machine learning, the aim is to find more robust QML algorithms, and some robust algorithms have indeed been proposed \cite{bib:wiebe2018hardening}. In addition to finding more robust algorithms, it's also important to understand the respective limitations on robustness, currently an open problem. A recent result suggests that the same quantum resource requirements may be necessary for detecting adversaries in higher dimensions as compared to quantum tomography \cite{bib:advql}. Thus, it remains unclear what the total resource cost of QML is in the presence of adversaries. However, there is the tantalising yet unexplored prospect that quantum resources may enhance the security of machine learning algorithms, in a similar way that information-theoretic security is afforded by quantum cryptographic protocols.

\paragraph{Other applications}

Whether or not there exist helpful QML techniques for traffic and routing management is currently very unclear, and may even appear unlikely. There may be some quantum-enhancements for machine learning algorithms applicable to traffic and routing management. However, the obstacle of efficient quantum encoding/decoding of classical data remains. The no-cloning theorem\index{No-cloning theorem} forbids state replication, and in general the overheads associated with encoding classical information into quantum states are very high \cite{bib:giovannetti2008quantum, bib:giovannetti2008architectures}, potentially outweighing any computational gain.

\subsubsection{Distributed quantum machine learning}\index{Distributed machine learning!Quantum}

The motives for considering distributed QML are similar to those for distributed classical machine learning. Suppose one wishes to perform distributed machine learning, either because the given data is naturally distributed or there is limited processing power on any given device. Then there are existing protocols for implementing general distributed quantum algorithms that might be helpful in delegating QML algorithms \cite{bib:beals2013efficient}.

Secure delegated quantum computational protocols \cite{bib:joe} can also be modified and applied to QML \cite{bib:sheng2017distributed, bib:bang2015protocol}. However, the same problem with state preparation could persist, for the server rather than the client. Alternatively, hybrid classical-quantum algorithms for distributed QML have been devised \cite{bib:yoo2014quantum}. Here, the quantum state preparation assumptions can be obviated by using a hybrid gate that takes in classical input data and implements classically-controlled unitary evolution.

\subsection{Machine learning with quantum data} \label{sec:ml_quantum_data}

Suppose our data is inherently quantum, in the form of quantum states or channels -- \textit{quantum data}\index{Quantum data}. We might additionally face restrictions in the number of copies we have access to, imposed by the no-cloning theorem\index{No-cloning theorem}.

In these cases, it has been found that classical machine learning methods may be helpful over traditional methods in dealing with quantum data. Another approach is to use quantum protocols to directly process quantum data. Learning protocols in the latter case belong to the field of quantum learning.

It is possible to process quantum data over both classical and quantum networks. Techniques from classical machine learning for quantum data may assist in the communication of quantum data over classical networks, while quantum learning protocols may be more appropriate over quantum networks. This is an exciting new research direction, as it is presently unclear whether such methods find utility.

\subsubsection{Classical machine learning for quantum data}

\paragraph{Tomography}\index{Tomography}

For classical processing of quantum data over a classical network, the first step is to find its classical description. The canonical methods for this are quantum state tomography\index{Quantum state tomography} and quantum process tomography\index{Quantum process tomography}. However, tomography is in general extremely resource intensive. Recent work has provided efficient methods for state tomography using classical machine learning techniques \cite{bib:Torlai2017, bib:Han2017}.

\paragraph{Separability}\index{Separability}

While tomography provides complete classical descriptions for quantum data, sometimes it may be sufficient to first classify data in terms of quantum characteristics. For instance, methods for classifying quantum states directly in terms of separability have been devised using classical machine learning \cite{bib:Ma2017, bib:Su2017, bib:Gao2018}. Here there are empirical demonstrations of some advantage compared to the CHSH inequality\index{CHSH inequality}. However, accumulating sufficient training data may still remain problematic for higher-dimensional states.

\paragraph{Automated experiment design}\index{Automated experiment design}

In a future quantum internet, it is desirable to find optimal methods for generating inter-node entanglement. It's also desirable for this process to be automated. Recently, such automated methods based on classical reinforcement learning \cite{bib:alexey} have been proposed to experimentally create a variety of entangled states, providing an exciting starting point for automated design in future quantum internet protocols.

\paragraph{Variational quantum eigensolvers}\index{Variational quantum eigensolvers}

We saw that variational quantum eigensolvers (VQE) rely on classical optimisation. When applied to quantum data, they have found success mostly in quantum chemistry \cite{bib:peruzzo2014peruzzo, bib:moll2018quantum}\index{Quantum chemistry}. In the context of quantum networks, the most promising developments are perhaps in its applicability to quantum data compression\index{Quantum data compression} \cite{bib:jonromero}, which may improve quantum data communication.

\subsubsection{Quantum learning protocols}

\paragraph{Template matching}\index{Template matching}

The first quantum algorithms for processing quantum data most relevant to machine learning were quantum template-matching algorithms \cite{bib:sasaki1, bib:sasaki2}. These are classification algorithms\index{Classification algorithms}, where each class is represented by a quantum state: a `template'. The task is to find the class to which a given test quantum state belongs, where this state is not identical to any of the template states. It is unclear whether quantum template matching is directly applicable to quantum networks. However, the ideas introduced provide the key foundations for supervised learning of quantum data, which can be used in the quantum counterparts to supervised algorithms in traffic prediction, classification, and anomaly detection.

\paragraph{Learning quantum processes}

Suppose we want to transmit just enough information about a quantum process over a quantum network in order for the other parties to replicate it. For quantum data, we don't have access to the classical description a priori. Instead, we are only allowed to query the process a finite number of times. For a unitary operation, this problem is addressed in \cite{bib:bisio_optimal_2010}, in a problem called the \textit{quantum learning of unitary operations}. A very interesting observation here is that the optimal strategy is semi-classical rather than fully-quantum, meaning it's sufficient for the classical data encoding the estimation of the unknown unitary to be stored. It remains an open question as to whether this extends to more general quantum processes.

\paragraph{Security}\index{Security}

In a future quantum network communicating quantum data, it becomes important to detect unusual behaviour in the incoming data-stream. These may present the first signs of a security breach or fault in the network. For dynamic time-series data, this is addressed by change point detection\index{Change point detection}. This has been extended to the quantum domain \cite{bib:gael1, bib:gael2}, where the optimal methods for detecting changes in quantum data are found using methods from state discrimination. For static data, anomaly detection methods based on machine learning become more appropriate as the definition of unusual behaviour is based on a priori training data. Classical anomaly detection algorithms have been applied to quantum data for the purpose of error detection \cite{bib:sara}, in the case where the classical description for quantum data is known. However, for cases where this classical description is unknown (as expected over a quantum internet), it is instead far more efficient to directly apply quantum algorithms. Examples of this include several quantum algorithms for anomaly detection \cite{bib:liu2018quantum}.